{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# First Challenge TheBigBatchTheory\n",
        "Notebook of the first challenge for the AN2DL course 2025-2026\n",
        "\n",
        "Components:\n",
        "- Benedetta Mussini\n",
        "- Andrea Rossi\n",
        "- Fabio Rossi\n",
        "- Francesco Sarra"
      ],
      "metadata": {
        "id": "5TxB1s_1lOz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Import"
      ],
      "metadata": {
        "id": "344WPJgslneu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OvKaycTb1au"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "# from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "logs_dir = \"tensorboard\"\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p models\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline\n",
        "\n",
        "# Define dataset names and their corresponding Google Drive URLs\n",
        "dataset_names = [\n",
        "    \"pirate_pain_train.csv\",\n",
        "    \"pirate_pain_train_labels.csv\",\n",
        "    \"pirate_pain_test.csv\"\n",
        "]\n",
        "\n",
        "dataset_URLs = {\n",
        "    dataset_names[0]: \"1hgDec_3kcDrM6voSSvzhxW4oBlot46fQ\",\n",
        "    dataset_names[1]: \"1TgebFnodrCFVme4Rha3kZVgFfW114qb2\",\n",
        "    dataset_names[2]: \"12F3ckAhM39q8D3S5zBDU1Smb1FK8eygr\"\n",
        "}\n",
        "\n",
        "# Loop through each dataset and download if not already present\n",
        "for name in dataset_names:\n",
        "    if not os.path.exists(name):\n",
        "        print(f\"Downloading {name}...\")\n",
        "        !gdown -q {dataset_URLs[name]} -O {name}\n",
        "        print(f\"{name} downloaded!\")\n",
        "    else:\n",
        "        print(f\"{name} already downloaded. Using cached data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Profiling"
      ],
      "metadata": {
        "id": "cqA-eQ3PmJ77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -U ydata-profiling[notebook]\n",
        "!pip install jupyter-contrib-nbextensions\n",
        "\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "!pip install dataprofiler\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "import json\n",
        "\n",
        "df = pd.read_csv('pirate_pain_train.csv')\n",
        "report = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
        "report.to_file(\"report.html\")\n",
        "report"
      ],
      "metadata": {
        "id": "OYf6o0Y1mCn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Considerations\n",
        "\n",
        "After performing an extensive exploration of the dataset, we applied several preprocessing steps to reduce noise, handle redundancy, address multicollinearity, and ensure that the downstream neural models would operate on a clean and informative feature space.\n",
        "\n",
        "We first inspected the three pirate-related features (n_legs, n_hands, n_eyes), which were stored as strings. These columns were mapped into numeric values using a consistent dictionary, and we verified that the same transformation was applied to the test set to avoid unseen categories. A subsequent analysis revealed that these three variables always carried identical information; therefore, we merged them into a single synthetic feature called pirate, dropping the original columns to remove perfect redundancy.\n",
        "\n",
        "Given the strong correlations observed across several groups of joint features, we applied PCA to selected subsets (joint_00–05, joint_06–07, joint_08–09, joint_10–11, and joint_26–29). This dimensionality reduction step allowed us to compress highly correlated signals while retaining most of the original variance. All scaling operations were performed with a StandardScaler fitted only on the training data to prevent data leakage. After PCA, the original joint columns used in each block were removed from all datasets.\n",
        "\n",
        "Before moving into model training, we additionally filtered out joint features with negligible predictive strength. To achieve this, we one-hot encoded the target labels and computed correlations between each joint and the three resulting indicator columns. We performed this analysis specifically on joints that were mostly zero-valued (almost always inactive) with only occasional spikes, since these sparse features tend to produce unstable or misleading correlations if evaluated over the full dataset. For each of these joints, correlations were calculated only on non-zero samples. If the absolute correlation consistently remained within the interval [−0.3,0.3], the feature was deemed uninformative and was removed from the training, validation and test sets.\n",
        "\n",
        "The survey features (pain_survey_1–4) were categorical rather than ordinal, and therefore we applied One-Hot Encoding to all of them. This expanded the feature space but ensured that their categorical semantics were handled correctly without imposing artificial order.\n",
        "\n",
        "To avoid leakage across individuals, the train/validation split was performed at the level of unique sample_index, ensuring temporal sequences from the same subject never appeared in both sets.\n",
        "\n",
        "Normalization was applied to all PCA-derived and continuous features using min–max scaling. Importantly, the scaling parameters were computed only from the training set, ensuring consistent but leakage-free transformations on validation and test sets.\n",
        "\n",
        "Finally, since the dataset is imbalanced we computed log-scaled class weights to stabilise learning and avoid dominance by majority classes. These weights were normalised and passed to the loss function."
      ],
      "metadata": {
        "id": "qYq-QecnnzKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration and Preprocessing"
      ],
      "metadata": {
        "id": "uWxkZjrrmXzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "df = pd.read_csv('pirate_pain_train.csv')\n",
        "df_test = pd.read_csv('pirate_pain_test.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4p4Yq2wGnV20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map strings in n_legs/n_hands/n_eyes to numbers\n",
        "num_map = {'one+hook_hand':1, 'one+eye_patch':1, 'two':2, 'one+peg_leg':1}\n",
        "for col in ['n_legs','n_hands','n_eyes']:\n",
        "    if col in df.columns and df[col].dtype == 'O':\n",
        "        df[col] = df[col].map(num_map).astype('float32')\n",
        "        df_test[col] = df_test[col].map(num_map).astype('float32')\n",
        "\n",
        "# Substitute 'n_eyes', 'n_legs', 'n_hands' columns with 'pirate' column if all three columns have the same values\n",
        "if (df['n_eyes'] - df['n_legs']).nunique() and (df['n_eyes'] - df['n_hands']).nunique() and (df['n_hands'] - df['n_legs']).nunique() :\n",
        "  df.drop('n_eyes', axis=1, inplace=True)\n",
        "  df.drop('n_hands', axis=1, inplace=True)\n",
        "  df['pirate']=df['n_legs']\n",
        "  df.drop('n_legs', axis=1, inplace=True)\n",
        "\n",
        "if (df_test['n_eyes'] - df_test['n_legs']).nunique() and (df_test['n_eyes'] - df_test['n_hands']).nunique() and (df_test['n_hands'] - df_test['n_legs']).nunique() :\n",
        "  df_test.drop('n_eyes', axis=1, inplace=True)\n",
        "  df_test.drop('n_hands', axis=1, inplace=True)\n",
        "  df_test['pirate']=df_test['n_legs']\n",
        "  df_test.drop('n_legs', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZXH_WrpZmbTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA on high correlations columns\n",
        "def apply_pca(df, df_test, columns_to_pca, n_components, new_columns_name):\n",
        "\n",
        "    #Select column to perform pca on\n",
        "    df_subset = df[columns_to_pca]\n",
        "\n",
        "    #Data scaling\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(df_subset)\n",
        "    scaled_data_test = scaler.transform(df_test[columns_to_pca])\n",
        "\n",
        "    #Apply PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    principal_components = pca.fit_transform(scaled_data)\n",
        "    principal_components_test = pca.transform(scaled_data_test)\n",
        "\n",
        "    #Analyze results\n",
        "    print(f\"Numero di componenti selezionate: {pca.n_components_}\")\n",
        "    print(f\"Varianza spiegata da ciascuna componente: {pca.explained_variance_ratio_}\")\n",
        "\n",
        "    #Create a new DataFrame with the principal components\n",
        "    pc_columns = new_columns_name\n",
        "    df_pca = pd.DataFrame(data=principal_components, columns=pc_columns)\n",
        "    df_pca_test  = pd.DataFrame(data=principal_components_test,  columns=new_columns_name)\n",
        "\n",
        "    # Merge new components to the original DataFrame removing the old ones.\n",
        "    # Reset indexes\n",
        "    df_reset = df.reset_index(drop=True)\n",
        "    df_test_reset = df_test.reset_index(drop=True)\n",
        "    df_pca_final = pd.concat([df_reset, df_pca], axis=1)\n",
        "    df_test_final = pd.concat([df_test_reset, df_pca_test], axis=1)\n",
        "\n",
        "    # Remove original columns\n",
        "    df_pca_final = df_pca_final.drop(columns=columns_to_pca)\n",
        "    df_test_final = df_test_final.drop(columns=columns_to_pca)\n",
        "\n",
        "    print(f\"PCA applied to {columns_to_pca}\")\n",
        "\n",
        "    return df_pca_final , df_test_final\n",
        "\n",
        "df, df_test = apply_pca(df=df, df_test=df_test, columns_to_pca=['joint_00', 'joint_01', 'joint_02', 'joint_03', 'joint_04', 'joint_05'], n_components=2, new_columns_name=['joint_00-05_x', 'joint_00-05_y'])\n",
        "df, df_test = apply_pca(df=df, df_test=df_test, columns_to_pca=['joint_06', 'joint_07'], n_components=1, new_columns_name=['joint_06-07'])\n",
        "df, df_test = apply_pca(df=df, df_test=df_test, columns_to_pca=['joint_08', 'joint_09'], n_components=1, new_columns_name=['joint_08-09'])\n",
        "df, df_test = apply_pca(df=df, df_test=df_test, columns_to_pca=['joint_10', 'joint_11'], n_components=1, new_columns_name=['joint_10-11'])\n",
        "df, df_test = apply_pca(df=df, df_test=df_test, columns_to_pca=['joint_26', 'joint_27', 'joint_28', 'joint_29'], n_components=2, new_columns_name=['joint_26-29_x', 'joint_26-29_y'])"
      ],
      "metadata": {
        "id": "0hSOHJkrnAT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop column joint_30 because constant\n",
        "df = df.drop('joint_30', axis=1)\n",
        "df_test = df_test.drop('joint_30', axis=1)\n",
        "\n",
        "# One-Hot Encoding on 'label' column (to explore correlation)\n",
        "y_train = pd.read_csv('pirate_pain_train_labels.csv')\n",
        "label_col = [c for c in y_train.columns if c != 'sample_index'][0]\n",
        "df = df.merge(y_train[['sample_index', label_col]], on='sample_index', how='left')\n",
        "label_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2,\n",
        "}\n",
        "\n",
        "df['label'] = df['label'].map(label_mapping)\n",
        "\n",
        "# dataset to explore correlation\n",
        "df_exploration = pd.get_dummies(df, columns=['label'], prefix='label')"
      ],
      "metadata": {
        "id": "Ou61S91IpJRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with low correlation with 'label'\n",
        "# Define columns to be handled\n",
        "joint_columns = ['joint_13', 'joint_14', 'joint_15', 'joint_16', 'joint_17', 'joint_18',\n",
        "       'joint_19', 'joint_20', 'joint_21', 'joint_22', 'joint_23', 'joint_24',\n",
        "       'joint_25']\n",
        "\n",
        "# Define new OHE columns\n",
        "ohe_label_columns = ['label_0', 'label_1', 'label_2']\n",
        "\n",
        "# List to compare ohe with the current column\n",
        "columns_to_correlate = []\n",
        "\n",
        "print(\"--- Calcolo Correlazioni (filtrate) dopo OHE ---\\n\")\n",
        "\n",
        "for j in joint_columns:\n",
        "    df_filtered = df_exploration[df_exploration[j] != 0]\n",
        "\n",
        "    # Select current column and the ohe columns\n",
        "    columns_to_correlate = [j] + ohe_label_columns\n",
        "\n",
        "    # Calculate correlation matrix on the column subset\n",
        "    correlation_matrix = df_filtered[columns_to_correlate].corr()\n",
        "\n",
        "    # Print correlation values\n",
        "\n",
        "    print(f\"--- Correlazioni per {j} (dove {j} != 0) ---\")\n",
        "\n",
        "    print(correlation_matrix[j].drop(j))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Drop columns that have correlation lower than 0.3 (in absolute value) wit 'label'\n",
        "    if (correlation_matrix[j].drop(j).min() > -0.3) and (correlation_matrix[j].drop(j).max() <0.3):\n",
        "        print(f\"Drop column {j}. Min = {correlation_matrix[j].min()}, max = {correlation_matrix[j].max()}\")\n",
        "        df_exploration.drop(j, axis=1, inplace=True)\n",
        "        df.drop(j, axis=1, inplace=True)\n",
        "        df_test.drop(j, axis=1, inplace=True)\n",
        "    else:\n",
        "      print(f\"Min = {correlation_matrix[j].drop(j).min()}, max = {correlation_matrix[j].drop(j).max()}\")\n"
      ],
      "metadata": {
        "id": "I1foAJ85p3dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding on pain_survey\n",
        "# Define columns to be encoded\n",
        "survey_columns = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\n",
        "\n",
        "# Apply One-Hot Encoding on them\n",
        "df_exploration = pd.get_dummies(df_exploration, columns=survey_columns)\n",
        "df = pd.get_dummies(df, columns=survey_columns)\n",
        "df_test = pd.get_dummies(df_test, columns=survey_columns)"
      ],
      "metadata": {
        "id": "JI8SaFskqd7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the final dataset for training\n",
        "df.head()"
      ],
      "metadata": {
        "id": "AauZWXZJqq_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split Train/Validation and normalization"
      ],
      "metadata": {
        "id": "1IFHd8KGqx73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PERCENTAGE_VALIDATION = 0.1\n",
        "\n",
        "# Obtain unique subject IDs\n",
        "unique_samples = df['sample_index'].unique()\n",
        "random.shuffle(unique_samples)\n",
        "\n",
        "# Split IDs\n",
        "n_train_subjects = int((1-PERCENTAGE_VALIDATION) * np.floor(len(unique_samples)))\n",
        "train_subjects = unique_samples[:n_train_subjects]\n",
        "val_subjects   = unique_samples[n_train_subjects:]\n",
        "\n",
        "# Create training and validation subsets\n",
        "df_train = df[df['sample_index'].isin(train_subjects)]\n",
        "df_val   = df[df['sample_index'].isin(val_subjects)]\n",
        "\n",
        "# Define the columns to be normalised\n",
        "scale_columns = ['joint_12', 'pirate', 'joint_00-05_x',\n",
        "       'joint_00-05_y', 'joint_06-07', 'joint_08-09', 'joint_10-11',\n",
        "       'joint_26-29_x', 'joint_26-29_y']\n",
        "\n",
        "# Calculate the minimum and maximum values from the training data only\n",
        "mins = df_train[scale_columns].min()\n",
        "maxs = df_train[scale_columns].max()\n",
        "\n",
        "df_test_pre_normalization = df_test.copy()\n",
        "\n",
        "# Apply normalisation to the specified columns in all datasets\n",
        "for column in scale_columns:\n",
        "    # Normalise the training set\n",
        "    df_train[column] = (df_train[column] - mins[column]) / (maxs[column] - mins[column])\n",
        "\n",
        "    # Normalise the validation set\n",
        "    df_val[column] = (df_val[column] - mins[column]) / (maxs[column] - mins[column])\n",
        "\n",
        "    # Normalise the test set\n",
        "    df_test[column] = (df_test[column] - mins[column]) / (maxs[column] - mins[column])\n"
      ],
      "metadata": {
        "id": "0WA22dpqrFR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computation of class weights for loss function (because of unbalanced training dataset)\n",
        "# Compute the counts of each class\n",
        "counts = np.bincount(df['label'])/160\n",
        "\n",
        "# Calculate weights using a logaritmich scale\n",
        "# log1p è log(1+x), che gestisce conteggi molto piccoli in modo stabile\n",
        "weights = 1.0 / np.log1p(counts)\n",
        "\n",
        "# Normalize weights\n",
        "weights = weights / np.sum(weights) * len(counts)\n",
        "\n",
        "print(f\"Counts: {counts}\")\n",
        "print(f\"Weights: {weights}\")\n",
        "\n",
        "# Convert the weights to a tensor\n",
        "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)"
      ],
      "metadata": {
        "id": "Xd3vIfU8rRhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns for training (feature columns)\n",
        "DATA_COLUMNS = df_train.columns.tolist()\n",
        "for c in ['sample_index', 'time', 'label']:\n",
        "  DATA_COLUMNS.remove(c)\n",
        "DATA_COLUMNS"
      ],
      "metadata": {
        "id": "Tnmuajl3rfcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Definition"
      ],
      "metadata": {
        "id": "qWB_oGD3rtOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build sequences from the dataset\n",
        "def build_sequences(df, window=200, stride=200):\n",
        "\n",
        "    # Initialise lists to store sequences and their corresponding labels\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over unique IDs in the DataFrame\n",
        "    for id in df['sample_index'].unique():\n",
        "        # Extract sensor data for the current ID\n",
        "        temp = df[df['sample_index'] == id][DATA_COLUMNS].values\n",
        "\n",
        "        # Retrieve the activity label for the current ID\n",
        "        label = df[df['sample_index'] == id]['label'].values[0]\n",
        "\n",
        "        # Calculate padding length to ensure full windows\n",
        "        padding_len = window - len(temp) % window\n",
        "\n",
        "        # Create zero padding and concatenate with the data\n",
        "        padding = np.zeros((padding_len, len(DATA_COLUMNS)), dtype='float32')\n",
        "        temp = np.concatenate((temp, padding))\n",
        "\n",
        "        # Build feature windows and associate them with labels\n",
        "        idx = 0\n",
        "        while idx + window <= len(temp):\n",
        "            dataset.append(temp[idx:idx + window])\n",
        "            labels.append(label)\n",
        "            idx += stride\n",
        "\n",
        "    # Convert lists to numpy arrays for further processing\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return dataset, labels\n",
        "\n",
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )\n",
        "\n",
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Generic RNN classifier (RNN, LSTM, GRU).\n",
        "    Uses the last hidden state for classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            num_classes,\n",
        "            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n",
        "            bidirectional=False,\n",
        "            dropout_rate=0.2\n",
        "            ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Map string name to PyTorch RNN class\n",
        "        rnn_map = {\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM,\n",
        "            'GRU': nn.GRU\n",
        "        }\n",
        "\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "\n",
        "        # Dropout is only applied between layers (if num_layers > 1)\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
        "\n",
        "        # Create the recurrent layer\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_val\n",
        "        )\n",
        "\n",
        "        # Calculate input size for the final classifier\n",
        "        if self.bidirectional:\n",
        "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
        "        else:\n",
        "            classifier_input_size = hidden_size\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        rnn_out, hidden = self.rnn(x)\n",
        "\n",
        "        # LSTM returns (h_n, c_n), we only need h_n\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            hidden = hidden[0]\n",
        "\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
        "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "\n",
        "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
        "            # Final shape: (batch_size, hidden_size * 2)\n",
        "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
        "        else:\n",
        "            # Take the last layer's hidden state\n",
        "            # Final shape: (batch_size, hidden_size)\n",
        "            hidden_to_classify = hidden[-1]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.classifier(hidden_to_classify)\n",
        "        return logits\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "\n",
        "            loss = loss + l1_lambda * l1_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1\n",
        "\n",
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Check if the tensor is not empty before adding a histogram\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                # Check if the gradient tensor is not empty before adding a histogram\n",
        "                if param.grad.numel() > 0:\n",
        "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
        "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)\n",
        "\n",
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        learning_rate, l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\",\n",
        "        mode='max', restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement:\n",
        "                best_metric = current_metric\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "                torch.save(model, \"models/\"+experiment_name+'_model.pth')\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
        "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0:\n",
        "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history\n",
        "\n",
        "def build_sequences_test(df, window=200, stride=200):\n",
        "\n",
        "    dataset = []\n",
        "    user_ids = []\n",
        "\n",
        "    for uid in df['sample_index'].unique():\n",
        "        temp = df[df['sample_index'] == uid][DATA_COLUMNS].values\n",
        "        padding_len = window - len(temp) % window\n",
        "        if padding_len != window:\n",
        "            padding = np.zeros((padding_len, len(DATA_COLUMNS)), dtype='float32')\n",
        "            temp = np.concatenate((temp, padding))\n",
        "\n",
        "        idx = 0\n",
        "        while idx + window <= len(temp):\n",
        "            dataset.append(temp[idx:idx + window])\n",
        "            user_ids.append(uid)\n",
        "            idx += stride\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    user_ids = np.array(user_ids)\n",
        "\n",
        "    return dataset, user_ids"
      ],
      "metadata": {
        "id": "s-vTskD8rx5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(rnn_type, bidirectional, window_size, stride, batch_size, experiment_name, learning_rate=1e-3, epochs=500, patience=50, dropout_rate=0.2, l1_lambda=0, l2_lambda=0, hidden_layers=2, hidden_size=128, criterion=nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1), verbose=0):\n",
        "  '''\n",
        "  Runs the model with the given parameters.\n",
        "  Requires rnn_type, bidirectional, window_size, stride, batch_size and experiment_name the rest is optional\n",
        "  '''\n",
        "  print(f\"Training {experiment_name}\")\n",
        "\n",
        "  # Generate sequences and labels for the training set\n",
        "  X_train, y_train = build_sequences(df_train, window_size, stride)\n",
        "  X_train = np.array(X_train, dtype=np.float32)\n",
        "\n",
        "  # Generate sequences and labels for the validation set\n",
        "  X_val, y_val = build_sequences(df_val, window_size, stride)\n",
        "  X_val = np.array(X_val, dtype=np.float32)\n",
        "\n",
        "  # Define the input shape based on the training data\n",
        "  input_shape = X_train.shape[1:]\n",
        "\n",
        "  # Define the number of classes based on the categorical labels\n",
        "  num_classes = len(np.unique(y_train))\n",
        "\n",
        "  # Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
        "  train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "  val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "\n",
        "  # Create data loaders with different settings for each phase\n",
        "  train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "  val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "  # Create model and display architecture with parameter count\n",
        "  rnn_model = RecurrentClassifier(\n",
        "      input_size=input_shape[-1], # Pass the number of features\n",
        "      hidden_size=hidden_size,\n",
        "      num_layers=hidden_layers,\n",
        "      num_classes=num_classes,\n",
        "      dropout_rate=dropout_rate,\n",
        "      bidirectional=bidirectional,\n",
        "      rnn_type=rnn_type\n",
        "      ).to(device)\n",
        "\n",
        "  # Define optimizer with L2 regularization\n",
        "  optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "\n",
        "  # Enable mixed precision training for GPU acceleration\n",
        "  scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "  # Set up TensorBoard logging and save model architecture\n",
        "  writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
        "  x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
        "  writer.add_graph(rnn_model, x)\n",
        "\n",
        "  # Train model and track training history\n",
        "  rnn_model, training_history = fit(\n",
        "      model=rnn_model,\n",
        "      train_loader=train_loader,\n",
        "      val_loader=val_loader,\n",
        "      epochs=epochs,\n",
        "      criterion=criterion,\n",
        "      optimizer=optimizer,\n",
        "      scaler=scaler,\n",
        "      device=device,\n",
        "      writer=writer,\n",
        "      verbose=verbose,\n",
        "      experiment_name=experiment_name,\n",
        "      patience=patience,\n",
        "      learning_rate=learning_rate,\n",
        "      l1_lambda=l1_lambda,\n",
        "      l2_lambda=l2_lambda\n",
        "      )"
      ],
      "metadata": {
        "id": "5aYx9Ql1s2iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "lF61YV5Ftnrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search\n",
        "rnn_types = ['RNN', 'LSTM']\n",
        "bidirectionals = [True, False]\n",
        "\n",
        "\n",
        "for t, b in product(rnn_types, bidirectionals):\n",
        "  experiment_name = f\"rnn_{t}_bidirectional_{b}\"\n",
        "  run_model(rnn_type = t, bidirectional=b, window_size=25, stride=2, batch_size=128, experiment_name=experiment_name, learning_rate=1e-3, epochs=500, patience=50, dropout_rate=0.3, l1_lambda=0, l2_lambda=0, hidden_layers=2, hidden_size=128, criterion=nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1), verbose=0)"
      ],
      "metadata": {
        "id": "axlxg2m_tpzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-shuffle cross validation"
      ],
      "metadata": {
        "id": "p8YQLyW6uO-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "K = 5\n",
        "N_VAL_USERS = int(PERCENTAGE_VALIDATION*np.floor(len(df['sample_index'].unique())))          # Number of users for validation split\n",
        "N_TEST_USERS = 0         # Number of users for test split\n",
        "\n",
        "# Training\n",
        "EPOCHS = 500             # Maximum epochs (increase to improve performance)\n",
        "PATIENCE = 100            # Early stopping patience (increase to improve performance)\n",
        "VERBOSE = 10             # Print frequency\n",
        "\n",
        "# Optimisation\n",
        "LEARNING_RATE = 1e-3     # Learning rate\n",
        "BATCH_SIZE = 512         # Batch size\n",
        "WINDOW_SIZE = 24        # Input window size\n",
        "STRIDE = 5              # Input stride\n",
        "\n",
        "# Architecture\n",
        "HIDDEN_LAYERS = 1        # Hidden layers\n",
        "HIDDEN_SIZE = 128        # Neurons per layer\n",
        "RNN_TYPE = 'RNN'         # Type of RNN architecture\n",
        "BIDIRECTIONAL = False    # Bidirectional RNN\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0.5       # Dropout probability\n",
        "L1_LAMBDA = 0.000001            # L1 penalty\n",
        "L2_LAMBDA = 0.001           # L2 penalty\n",
        "\n",
        "# Training utilities\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
        "\n",
        "def k_shuffle_split_cross_validation_round_rnn(df, epochs, criterion, device,\n",
        "                            k, n_val_users, n_test_users, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate,\n",
        "                            window_size, stride, rnn_type, bidirectional,\n",
        "                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "                            restore_best_weights=True, writer=None, verbose=10, seed=42, experiment_name=\"\",split_mins_list=None, split_maxs_list=None):\n",
        "    \"\"\"\n",
        "    Perform K-fold shuffle split cross-validation with user-based splitting for time series data.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n",
        "        epochs: Number of training epochs\n",
        "        criterion: Loss function\n",
        "        device: torch.device for computation\n",
        "        k: Number of cross-validation splits\n",
        "        n_val_users: Number of users for validation set\n",
        "        n_test_users: Number of users for test set\n",
        "        batch_size: Batch size for training\n",
        "        hidden_layers: Number of recurrent layers\n",
        "        hidden_size: Hidden state dimensionality\n",
        "        learning_rate: Learning rate for optimizer\n",
        "        dropout_rate: Dropout rate\n",
        "        window_size: Length of sliding windows\n",
        "        stride: Step size for sliding windows\n",
        "        rnn_type: Type of RNN ('RNN', 'LSTM', 'GRU')\n",
        "        bidirectional: Whether to use bidirectional RNN\n",
        "        l1_lambda: L1 regularization coefficient (if used)\n",
        "        l2_lambda: L2 regularization coefficient (weight_decay)\n",
        "        patience: Early stopping patience\n",
        "        evaluation_metric: Metric to monitor for early stopping\n",
        "        mode: 'max' or 'min' for evaluation metric\n",
        "        restore_best_weights: Whether to restore best weights after training\n",
        "        writer: TensorBoard writer\n",
        "        verbose: Verbosity level\n",
        "        seed: Random seed\n",
        "        experiment_name: Name for experiment logging\n",
        "\n",
        "    Returns:\n",
        "        fold_losses: Dict with validation losses for each split\n",
        "        fold_metrics: Dict with validation F1 scores for each split\n",
        "        best_scores: Dict with best F1 score for each split plus mean and std\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialise containers for results across all splits\n",
        "    fold_losses = {}\n",
        "    fold_metrics = {}\n",
        "    best_scores = {}\n",
        "\n",
        "    # Get model architecture parameters\n",
        "    in_features = len(DATA_COLUMNS)\n",
        "    num_classes = len(df['label'].unique())\n",
        "\n",
        "    # Initialise model architecture\n",
        "    model = RecurrentClassifier(\n",
        "        input_size=in_features,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=hidden_layers,\n",
        "        num_classes=num_classes,\n",
        "        dropout_rate=dropout_rate,\n",
        "        bidirectional=bidirectional,\n",
        "        rnn_type=rnn_type\n",
        "    ).to(device)\n",
        "\n",
        "    # Store initial weights to reset model for each split\n",
        "    initial_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Iterate through K random splits\n",
        "    for split_idx in range(k):\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"Split {split_idx+1}/{k}\")\n",
        "\n",
        "        # Get unique user IDs and shuffle them with split-specific seed\n",
        "        unique_users = df['sample_index'].unique()\n",
        "        random.seed(seed + split_idx)\n",
        "        random.shuffle(unique_users)\n",
        "\n",
        "        # Calculate the number of users for the training set\n",
        "        n_train_users = len(unique_users) - n_val_users - n_test_users\n",
        "\n",
        "        # Split the shuffled user IDs into training, validation, and test sets\n",
        "        train_users = unique_users[:n_train_users]\n",
        "        val_users = unique_users[n_train_users:n_train_users + n_val_users]\n",
        "        test_users = unique_users[n_train_users + n_val_users:]\n",
        "\n",
        "        # Split the dataset into training, validation, and test sets based on user IDs\n",
        "        df_train = df[df['sample_index'].isin(train_users)].copy()\n",
        "        df_val = df[df['sample_index'].isin(val_users)].copy()\n",
        "        df_test = df[df['sample_index'].isin(test_users)].copy()\n",
        "\n",
        "        # Define a mapping of activity names to integer labels\n",
        "        label_mapping = {\n",
        "            'no_pain': 0,\n",
        "            'low_pain': 1,\n",
        "            'high_pain': 2,\n",
        "        }\n",
        "\n",
        "        # Map label names to integers in the training set\n",
        "        df_train['label'] = df_train['label'].map(label_mapping)\n",
        "\n",
        "        # Map label names to integers in the validation set\n",
        "        df_val['label'] = df_val['label'].map(label_mapping)\n",
        "\n",
        "        # Map label names to integers in the test set\n",
        "        df_test['label'] = df_test['label'].map(label_mapping)\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training set shape: {df_train.shape}\")\n",
        "            print(f\"  Validation set shape: {df_val.shape}\")\n",
        "            print(f\"  Test set shape: {df_test.shape}\")\n",
        "\n",
        "        # Normalise features using training set statistics\n",
        "        train_max = df_train[DATA_COLUMNS].max()\n",
        "        train_min = df_train[DATA_COLUMNS].min()\n",
        "\n",
        "        if split_mins_list is not None and split_maxs_list is not None:\n",
        "          split_mins_list.append(train_min.copy())\n",
        "          split_maxs_list.append(train_max.copy())\n",
        "\n",
        "        df_train[DATA_COLUMNS] = (df_train[DATA_COLUMNS] - train_min) / (train_max - train_min + 1e-8)\n",
        "        df_val[DATA_COLUMNS] = (df_val[DATA_COLUMNS] - train_min) / (train_max - train_min + 1e-8)\n",
        "        df_test[DATA_COLUMNS] = (df_test[DATA_COLUMNS] - train_min) / (train_max - train_min + 1e-8)\n",
        "\n",
        "        # Build sequences using the existing build_sequences function\n",
        "        X_train, y_train = build_sequences(df_train, window=window_size, stride=stride)\n",
        "        X_val, y_val = build_sequences(df_val, window=window_size, stride=stride)\n",
        "        X_test, y_test = build_sequences(df_test, window=window_size, stride=stride)\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training sequences shape: {X_train.shape}\")\n",
        "            print(f\"  Validation sequences shape: {X_val.shape}\")\n",
        "            print(f\"  Test sequences shape: {X_test.shape}\")\n",
        "\n",
        "        # Create PyTorch datasets\n",
        "        train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "        val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "        test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "        test_loader  = make_loader(test_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        # Reset model to initial weights for fair comparison across splits\n",
        "        model.load_state_dict(initial_state)\n",
        "\n",
        "        # Define optimizer with L2 regularization\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "\n",
        "        # Enable mixed precision training for GPU acceleration\n",
        "        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "        # Create directory for model checkpoints\n",
        "        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n",
        "\n",
        "\n",
        "        writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n",
        "\n",
        "        # (Opzionale) aggiungi il grafo del modello una volta per split.\n",
        "        # Qui usiamo la shape reale dei dati: (window_size, n_features)\n",
        "        sample_shape = X_train.shape[1:]        # es. (WINDOW_SIZE, num_features)\n",
        "        dummy_input = torch.randn(1, *sample_shape).to(device)\n",
        "        writer.add_graph(model, dummy_input)\n",
        "\n",
        "        # Train model on current split\n",
        "        model, training_history = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=epochs,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scaler=split_scaler,\n",
        "            device=device,\n",
        "            writer=writer,\n",
        "            patience=patience,\n",
        "            verbose=verbose,\n",
        "            l1_lambda=l1_lambda,\n",
        "            evaluation_metric=evaluation_metric,\n",
        "            mode=mode,\n",
        "            restore_best_weights=restore_best_weights,\n",
        "            experiment_name=experiment_name+\"_split_\"+str(split_idx)\n",
        "        )\n",
        "\n",
        "        # Store results for this split\n",
        "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
        "        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n",
        "        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n",
        "\n",
        "    # Compute mean and standard deviation of best scores across splits\n",
        "    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"Best score: {best_scores['mean']:.4f}±{best_scores['std']:.4f}\")\n",
        "\n",
        "    return fold_losses, fold_metrics, best_scores\n",
        "\n",
        "def grid_search_cv_rnn(df, param_grid, fixed_params, cv_params, verbose=True):\n",
        "    \"\"\"\n",
        "    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n",
        "        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n",
        "        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n",
        "        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n",
        "        verbose: Print progress for each configuration\n",
        "\n",
        "    Returns:\n",
        "        results: Dict with scores for each configuration\n",
        "        best_config: Dict with best hyperparameter combination\n",
        "        best_score: Best mean F1 score achieved\n",
        "    \"\"\"\n",
        "    # Generate all parameter combinations\n",
        "    param_names = list(param_grid.keys())\n",
        "    param_values = list(param_grid.values())\n",
        "    combinations = list(product(*param_values))\n",
        "\n",
        "    results = {}\n",
        "    best_score = -np.inf\n",
        "    best_config = None\n",
        "\n",
        "    total = len(combinations)\n",
        "\n",
        "    for idx, combo in enumerate(combinations, 1):\n",
        "        # Create current configuration dict\n",
        "        current_config = dict(zip(param_names, combo))\n",
        "\n",
        "        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])+f\"validation_percentage_{PERCENTAGE_VALIDATION}\"\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nConfiguration {idx}/{total}:\")\n",
        "            for param, value in current_config.items():\n",
        "                print(f\"  {param}: {value}\")\n",
        "\n",
        "        # Merge current config with fixed parameters\n",
        "        run_params = {**fixed_params, **current_config}\n",
        "\n",
        "        # Execute cross-validation\n",
        "        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n",
        "            df=df,\n",
        "            experiment_name=config_str,\n",
        "            **run_params,\n",
        "            **cv_params\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        results[config_str] = fold_scores\n",
        "\n",
        "        # Track best configuration\n",
        "        if fold_scores[\"mean\"] > best_score:\n",
        "            best_score = fold_scores[\"mean\"]\n",
        "            best_config = current_config.copy()\n",
        "            if verbose:\n",
        "                print(\"  NEW BEST SCORE!\")\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  F1 Score: {fold_scores['mean']:.4f}±{fold_scores['std']:.4f}\")\n",
        "\n",
        "    return results, best_config, best_score\n",
        "\n",
        "\n",
        "def plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n",
        "    \"\"\"\n",
        "    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n",
        "\n",
        "    Args:\n",
        "        results: Dict of results from grid_search_cv_rnn\n",
        "        k_splits: Number of CV splits used\n",
        "        top_n: Number of top configurations to display\n",
        "        figsize: Figure size tuple\n",
        "    \"\"\"\n",
        "    # Sort by mean score\n",
        "    config_scores = {name: data['mean'] for name, data in results.items()}\n",
        "    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select top N\n",
        "    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n",
        "\n",
        "    # Prepare boxplot data\n",
        "    boxplot_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Define a dictionary for replacements, ordered to handle prefixes correctly\n",
        "    replacements = {\n",
        "        'batch_size_': 'BS=',\n",
        "        'learning_rate_': '\\nLR=',\n",
        "        'hidden_layers_': '\\nHL=',\n",
        "        'hidden_size_': '\\nHS=',\n",
        "        'dropout_rate_': '\\nDR=',\n",
        "        'window_size_': '\\nWS=',\n",
        "        'stride_': '\\nSTR=',\n",
        "        'rnn_type_': '\\nRNN=',\n",
        "        'bidirectional_': '\\nBIDIR=',\n",
        "        'l1_lambda_': '\\nL1=',\n",
        "        'l2_lambda_': '\\nL2='\n",
        "    }\n",
        "\n",
        "    # Replacements for separators\n",
        "    separator_replacements = {\n",
        "        '_learning_rate_': '\\nLR=',\n",
        "        '_hidden_layers_': '\\nHL=',\n",
        "        '_hidden_size_': '\\nHS=',\n",
        "        '_dropout_rate_': '\\nDR=',\n",
        "        '_window_size_': '\\nWS=',\n",
        "        '_stride_': '\\nSTR=',\n",
        "        '_rnn_type_': '\\nRNN=',\n",
        "        '_bidirectional_': '\\nBIDIR=',\n",
        "        '_l1_lambda_': '\\nL1=',\n",
        "        '_l2_lambda_': '\\nL2=',\n",
        "        '_': ''\n",
        "    }\n",
        "\n",
        "    for config_name, mean_score in top_configs:\n",
        "        # Extract best score from each split (auto-detect number of splits)\n",
        "        split_scores = []\n",
        "        for i in range(k_splits):\n",
        "            if f'split_{i}' in results[config_name]:\n",
        "                split_scores.append(results[config_name][f'split_{i}'])\n",
        "        boxplot_data.append(split_scores)\n",
        "\n",
        "        # Verify we have the expected number of splits\n",
        "        if len(split_scores) != k_splits:\n",
        "            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n",
        "\n",
        "        # Create readable label using the replacements dictionary\n",
        "        readable_label = config_name\n",
        "        for old, new in replacements.items():\n",
        "            readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        # Apply separator replacements\n",
        "        for old, new in separator_replacements.items():\n",
        "             readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        labels.append(f\"{readable_label}\\n(μ={mean_score:.3f})\")\n",
        "\n",
        "    # Create plot\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n",
        "                    showmeans=True, meanline=True)\n",
        "\n",
        "    # Styling\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('lightblue')\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    # Highlight best configuration\n",
        "    ax.get_xticklabels()[0].set_fontweight('bold')\n",
        "\n",
        "    ax.set_ylabel('F1 Score')\n",
        "    ax.set_xlabel('Configuration')\n",
        "    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.xticks(rotation=0, ha='center')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-mh9aBfvuVGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#submissionLSTM_BITrue_HS64_HL1_DR0.3_LR0.001.csv\n",
        "# Define parameters to search\n",
        "param_grid = {\n",
        "    'window_size': [24],\n",
        "    'stride': [2],\n",
        "    'rnn_type': ['GRU'],\n",
        "    'batch_size': [512],\n",
        "    'bidirectional' : [False]\n",
        "}\n",
        "\n",
        "# Fixed hyperparameters (not being tuned)\n",
        "fixed_params = {\n",
        "    'learning_rate': 0.0005,\n",
        "    'hidden_layers': 2,\n",
        "    'hidden_size': 192,\n",
        "    'dropout_rate': 0.3,\n",
        "    'l1_lambda': 0,\n",
        "    'l2_lambda': 0.0015,\n",
        "}\n",
        "\n",
        "split_mins = []\n",
        "split_maxs = []\n",
        "\n",
        "# Cross-validation settings\n",
        "cv_params = {\n",
        "    'epochs': EPOCHS,\n",
        "    'criterion': criterion,\n",
        "    'device': device,\n",
        "    'k': K,\n",
        "    'n_val_users': int(N_VAL_USERS),\n",
        "    'n_test_users': int(N_TEST_USERS),\n",
        "    'patience': PATIENCE,\n",
        "    'verbose': 10,\n",
        "    'seed': SEED,\n",
        "    'split_mins_list': split_mins,\n",
        "    'split_maxs_list': split_maxs\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Execute search\n",
        "results, best_config, best_score = grid_search_cv_rnn(\n",
        "    df=df,\n",
        "    param_grid=param_grid,\n",
        "    fixed_params=fixed_params,\n",
        "    cv_params=cv_params\n",
        ")\n"
      ],
      "metadata": {
        "id": "qWpKwBVKvBFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ],
      "metadata": {
        "id": "o_BlWTlhyOSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = []\n",
        "name=\"\"\n",
        "for i in range(K):\n",
        "    MODEL_PATH.append(\"models/\"+name+\"_split_\"+str(i)+\"_model.pth\")\n",
        "BATCH_SIZE_TEST = 512\n",
        "WINDOW_SIZE_TEST = 24\n",
        "STRIDE_TEST = 2\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Prepare df_test after preprocessing and before normalization\n",
        "# ==============================\n",
        "df_test_raw = df_test_pre_normalization.copy()\n",
        "\n",
        "# ==============================\n",
        "# Build K versions of df_test and normalize with the correct split\n",
        "# ==============================\n",
        "test_loaders = []\n",
        "user_ids_ref = None\n",
        "\n",
        "# split_mins e split_maxs devono essere liste di Series, una per split\n",
        "assert len(split_mins) == len(MODEL_PATHS) == len(split_maxs), \"Mismatch between split_mins/split_maxs and MODEL_PATHS\"\n",
        "\n",
        "for split_idx, (train_min, train_max) in enumerate(zip(split_mins, split_maxs)):\n",
        "    print(f\"Preparing test set for split {split_idx}...\")\n",
        "\n",
        "    # df_test copy\n",
        "    df_test_i = df_test_raw.copy()\n",
        "\n",
        "    # normalization for this split\n",
        "    df_test_i[scale_columns] = (df_test_i[scale_columns] - train_min[scale_columns]) / (\n",
        "        train_max[scale_columns] - train_min[scale_columns]\n",
        "    )\n",
        "\n",
        "    # Build test sequences for this split\n",
        "    X_test_i, user_ids = build_sequences_test(\n",
        "        df_test_i,\n",
        "        window=WINDOW_SIZE_TEST,\n",
        "        stride=STRIDE_TEST\n",
        "    )\n",
        "\n",
        "    # user_id consistency check between splits\n",
        "    if user_ids_ref is None:\n",
        "        user_ids_ref = user_ids\n",
        "    else:\n",
        "        if not np.array_equal(user_ids_ref, user_ids):\n",
        "            raise ValueError(\"user_ids different between split: check build_sequences_test!\")\n",
        "\n",
        "    X_test_i = np.array(X_test_i, dtype=np.float32)\n",
        "\n",
        "    test_ds_i = TensorDataset(torch.from_numpy(X_test_i))\n",
        "    test_loader_i = make_loader(\n",
        "        test_ds_i,\n",
        "        batch_size=BATCH_SIZE_TEST,\n",
        "        shuffle=False,\n",
        "        drop_last=False\n",
        "    )\n",
        "    test_loaders.append(test_loader_i)\n",
        "\n",
        "# Handle empty test sets from user splits\n",
        "if user_ids_ref is None or len(user_ids_ref) == 0:\n",
        "    print(\"WARNING: Test set is empty dopo la costruzione delle sequenze. Skipping.\")\n",
        "else:\n",
        "    user_ids = user_ids_ref\n",
        "\n",
        "    # ==============================\n",
        "    # K models ensemble\n",
        "    # ==============================\n",
        "    models = []\n",
        "    for path in MODEL_PATHS:\n",
        "        m = torch.load(path, map_location=device, weights_only=False)\n",
        "        m.to(device)\n",
        "        m.eval()\n",
        "        models.append(m)\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for model_idx, m in enumerate(models):\n",
        "            print(f\"Inferenza modello {model_idx}...\")\n",
        "            model_logits_batches = []\n",
        "\n",
        "            for xb in test_loaders[model_idx]:\n",
        "                xb = xb[0].to(device)\n",
        "                logits = m(xb)\n",
        "                model_logits_batches.append(logits.cpu().numpy())\n",
        "\n",
        "            if len(model_logits_batches) == 0:\n",
        "                continue\n",
        "\n",
        "            model_logits = np.concatenate(model_logits_batches, axis=0)\n",
        "            all_logits.append(model_logits)\n",
        "\n",
        "    if len(all_logits) == 0:\n",
        "        print(\"WARNING: Nessun logit prodotto dai modelli. Skipping.\")\n",
        "    else:\n",
        "        #Logits avarage for K splits\n",
        "        mean_logits = np.mean(all_logits, axis=0)  # (N_seq, num_classes)\n",
        "        split_test_preds = mean_logits.argmax(axis=1)\n",
        "\n",
        "        # ==============================\n",
        "        # User majority vote\n",
        "        # ==============================\n",
        "        final_preds = {}\n",
        "\n",
        "        for uid in np.unique(user_ids):\n",
        "            mask = user_ids == uid\n",
        "            user_preds = split_test_preds[mask]\n",
        "            majority_class = Counter(user_preds).most_common(1)[0][0]\n",
        "            final_preds[uid] = majority_class\n",
        "\n",
        "        #Converts numerical predictions into literal\n",
        "        label_map = {0: \"no_pain\", 1: \"low_pain\", 2: \"high_pain\"}\n",
        "\n",
        "        submission_data = []\n",
        "        for uid, pred_num in final_preds.items():\n",
        "            label_str = label_map[pred_num]\n",
        "            submission_data.append((f\"{int(uid):03d}\", label_str))  # format\n"
      ],
      "metadata": {
        "id": "WKVJGHtiyQsR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}